{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3431319e-2e6b-43c1-a2f6-61ccba592c21",
   "metadata": {},
   "source": [
    "## Evaluating a vectorial function on CPU and GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d142183-b6bb-42e7-ba9d-35bf0f91dc0c",
   "metadata": {},
   "source": [
    "### CPU: plain and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b92dd336-9997-4323-80e4-f285e9cc2db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "8.14 ms ± 10.8 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "18.2 ms ± 76.9 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "18.1 ms ± 24.3 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit, jit\n",
    "\n",
    "# Python plain implementation w/ numba \n",
    "@njit\n",
    "def grade2_vector(x, y, a, b, c):\n",
    "    z = np.zeros(x.size)\n",
    "    for i in range(x.size):\n",
    "        z[i] = a*x[i]*x[i] + b*y[i] + c\n",
    "    return z\n",
    "\n",
    "# Numpy ufunc\n",
    "def grade2_ufunc(x, y, a, b, c):\n",
    "    return a*x**2 + b*y + c\n",
    "\n",
    "# size of the vectors\n",
    "size = 5_000_000\n",
    "\n",
    "# allocating and populating the vectors\n",
    "a_cpu = np.random.rand(size)\n",
    "b_cpu = np.random.rand(size)\n",
    "c_cpu = np.zeros(size)\n",
    "\n",
    "a = 3.5\n",
    "b = 2.8\n",
    "c = 10\n",
    "\n",
    "# Printing input values\n",
    "#print(a_cpu)\n",
    "#print(b_cpu)\n",
    "# Random function in Numpy always use float64\n",
    "print(a_cpu.dtype)\n",
    "\n",
    "c_cpu = grade2_vector(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "\n",
    "# Evaluating the time\n",
    "\n",
    "# Numba Python: huge improvement, better that numpy code\n",
    "%timeit -n 5 -r 2 grade2_vector(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "# w/ a numpy ufunc manually coded\n",
    "%timeit -n 5 -r 2 grade2_ufunc(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "# using the general numpy ufunc \n",
    "%timeit -n 5 -r 2 a*a_cpu**2 + b*b_cpu + c\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3e33cd9-07dc-4ec2-89ca-3fb25bbe1fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midiendo CuPy copiando los datos\n",
      "cupy_copia          :    CPU:  7783.355 us   +/- 12.573 (min:  7762.952 / max:  7800.776) us     GPU-0:  7788.275 us   +/- 12.451 (min:  7767.712 / max:  7805.312) us\n",
      "\n",
      "Midiendo CuPy sin copiar los datos\n",
      "cupy_sin_copia      :    CPU:    99.027 us   +/-  0.997 (min:    97.396 / max:    99.957) us     GPU-0:   902.022 us   +/-  1.173 (min:   899.936 / max:   903.136) us\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "from cupyx.profiler import benchmark\n",
    "\n",
    "#Paso a simple precisión (float32)\n",
    "a_cpu_32 = a_cpu.astype(np.float32)\n",
    "b_cpu_32 = b_cpu.astype(np.float32)\n",
    "\n",
    "def cupy_copia(x, y, a, b, c):\n",
    "    #Copia a GPU\n",
    "    x_gpu = cp.asarray(x)\n",
    "    y_gpu = cp.asarray(y)\n",
    "    res_gpu = a * x_gpu**2 + b * y_gpu + c\n",
    "    #Copia a CPU\n",
    "    return cp.asnumpy(res_gpu)\n",
    "\n",
    "print(\"Midiendo CuPy copiando los datos\")\n",
    "#Se usa benchmark de CuPy\n",
    "print(benchmark(cupy_copia, (a_cpu_32, b_cpu_32, a, b, c), n_repeat=5))\n",
    "\n",
    "#Sin copiar datos\n",
    "#Creamos los arrays en la GPU\n",
    "a_gpu_32 = cp.asarray(a_cpu_32)\n",
    "b_gpu_32 = cp.asarray(b_cpu_32)\n",
    "\n",
    "def cupy_sin_copia(x_gpu, y_gpu, a, b, c):\n",
    "    # Cálculo directo en GPU\n",
    "    return a * x_gpu**2 + b * y_gpu + c\n",
    "\n",
    "print(\"\\nMidiendo CuPy sin copiar los datos\")\n",
    "print(benchmark(cupy_sin_copia, (a_gpu_32, b_gpu_32, a, b, c), n_repeat=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb1298eb-9243-4f31-8d5a-0a6bb593669a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midiendo Numba con copia\n",
      "13.2 ms ± 3.56 ms per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "\n",
      "Midiendo Numba sin copia\n",
      "1.59 ms ± 101 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "from numba import vectorize, float32, cuda\n",
    "\n",
    "#ufunc para GPU\n",
    "@vectorize(['float32(float32, float32, float32, float32, float32)'], target='cuda')\n",
    "def grade2_numba_gpu(x, y, a, b, c):\n",
    "    return a * x**2 + b * y + c\n",
    "\n",
    "print(\"Midiendo Numba con copia\")\n",
    "%timeit -n 5 -r 2 grade2_numba_gpu(a_cpu_32, b_cpu_32, a, b, c)\n",
    "\n",
    "#Se hace la copia\n",
    "a_gpu = cuda.to_device(a_cpu_32)\n",
    "b_gpu = cuda.to_device(b_cpu_32)\n",
    "\n",
    "print(\"\\nMidiendo Numba sin copia\")\n",
    "%timeit -n 5 -r 2 grade2_numba_gpu(a_gpu, b_gpu, a, b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8bab22-504b-4f6b-9c82-2a85bcdcfd0e",
   "metadata": {},
   "source": [
    "### Resultados\n",
    "Analizando los tiempos de ejecución, en primer lugar se observa que hay una gran diferencia entre ejecutar el código con copia (alrededor de 7.8 ms en CuPy) y sin copia (alrededor de 1.0 ms en CuPy). Esto demuestra que mover los datos de la memoria de la CPU a la GPU supone más tiempo que el cálculo matemático. Para arrays de este tamaño (5 millones de elementos), la transferencia de datos ocupa la gran mayoría del tiempo total.\n",
    "\n",
    "En segundo lugar, respecto a la aceleración, se confirma que el cálculo en GPU (CuPy sin copia 1.0 ms) es mucho más rápido que la versión original de en CPU, demostando la utilidad de utilizar GPUs para operaciones de este tipo frente a la CPU.\n",
    "\n",
    "Por último, al comparar las dos librerías utilizadas, en este caso específico CuPy (1.0 ms) ha resultado más eficiente que Numba (1.5 ms) en la ejecución sin copia, aunque ambas mejoran mucho el rendimiento con respecto a la ejecución en CPU."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
